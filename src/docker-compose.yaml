version: '3'

# Define extension variables
x-superset-image: &superset-image apachesuperset.docker.scarf.sh/apache/superset:${TAG:-latest}
x-superset-depends-on: &superset-depends-on
  - superset-db
  - superset-cache
x-superset-volumes: &superset-volumes # /app/pythonpath_docker will be appended to the PYTHONPATH in the final container
  - ./superset/docker:/app/docker
  - superset_home:/app/superset_home

# Services
services:
  # App
  app:
    build:
      context: .
      dockerfile: ./Dockerfile
      args:
        - POETRY_VERSION=1.7.1
        - PROJECT_DIRNAME=${PROJECT_DIRNAME}
    container_name: app
    volumes:
      - ./${PROJECT_DIRNAME}:/app/${PROJECT_DIRNAME}
    ports:
      - 3000:3000
    environment:
      - AWS_REGION=${AWS_REGION}
      - AWS_DEFAULT_REGION=${AWS_REGION}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      # Required for pyiceberg to access iceberg-rest catalog
      - PYICEBERG_CATALOG__ICEBERGCATALOG__URI=http://iceberg-rest:8181
      - PYICEBERG_CATALOG__ICEBERGCATALOG__S3__ENDPOINT=${S3_ENDPOINT}
      - PYICEBERG_CATALOG__ICEBERGCATALOG__PY_IO_IMPL=pyiceberg.io.pyarrow.PyArrowFileIO
      - PYICEBERG_CATALOG__ICEBERGCATALOG__S3__REGION=${AWS_REGION}
      - PYICEBERG_CATALOG__ICEBERGCATALOG__S3__ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - PYICEBERG_CATALOG__ICEBERGCATALOG__S3__SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
    networks:
      - shared_network
    depends_on:
      - minio
      - iceberg-rest

  iceberg-rest:
    image: tabulario/iceberg-rest
    container_name: iceberg_rest
    networks:
      - shared_network
    ports:
      - 8181:8181
    environment:
      - AWS_REGION=${AWS_REGION}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - CATALOG_WAREHOUSE=s3a://${LAKEHOUSE_NAME}/
      - CATALOG_IO__IMPL=org.apache.iceberg.aws.s3.S3FileIO
      - CATALOG_S3_ENDPOINT=${S3_ENDPOINT}
      - CATALOG_CATALOG__IMPL=org.apache.iceberg.jdbc.JdbcCatalog
      - CATALOG_URI=jdbc:postgresql://pg-catalog:5432/${PG_CATALOG_DB}
      - CATALOG_JDBC_USER=${PG_CATALOG_USER}
      - CATALOG_JDBC_PASSWORD=${PG_CATALOG_PASSWORD}
    depends_on:
      - pg-catalog

  # Postgres for iceberg-rest storage
  pg-catalog:
    image: postgres:15-alpine
    container_name: pg_catalog
    environment:
      - POSTGRES_USER=${PG_CATALOG_USER}
      - POSTGRES_PASSWORD=${PG_CATALOG_PASSWORD}
      - POSTGRES_DB=${PG_CATALOG_DB}
    healthcheck:
      test: ['CMD', 'pg_isready', '-U', '${PG_CATALOG_USER}']
      interval: 5s
      retries: 5
    ports:
      - '5432:5432'
    volumes:
      - pg_catalog_data:/var/lib/postgresql/data
    networks:
      - shared_network

  # Minio Storage Server
  minio:
    image: minio/minio
    container_name: minio
    command: server --address "0.0.0.0:9000" --console-address "0.0.0.0:9001" /data
    restart: always
    environment:
      - MINIO_ROOT_USER=${AWS_ACCESS_KEY_ID}
      - MINIO_ROOT_PASSWORD=${AWS_SECRET_ACCESS_KEY}
      # - MINIO_DOMAIN=minio
      # - MINIO_REGION=${AWS_REGION}
      # - AWS_DEFAULT_REGION=${AWS_REGION}
    ports:
      - 9000:9000
      - 9001:9001
    volumes:
      - minio_data:/data
    networks:
      shared_network:
        aliases:
          - ${LAKEHOUSE_NAME}.minio # This is important for iceberg-rest to find minio to connect to

  # Minio Client - create the first bucket
  mc:
    image: minio/mc
    container_name: mc
    hostname: mc # some programs INSIDE the container will try to read the hostname
    environment:
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      # - MINIO_SITE_REGION=${AWS_REGION}
      # - AWS_REGION=${AWS_REGION}
      # - AWS_DEFAULT_REGION=${AWS_REGION}
    networks:
      - shared_network
    # `tail -f /dev/null` will ensure the terminal session remains open indefinitely - so the container doesn't exit
    entrypoint: >
      /bin/sh -c "
      until (/usr/bin/mc config host add minio ${S3_ENDPOINT} ${AWS_ACCESS_KEY_ID} ${AWS_SECRET_ACCESS_KEY}) do echo '...waiting...' && sleep 1; done;
      /usr/bin/mc mb minio/${LAKEHOUSE_NAME};
      /usr/bin/mc policy set public minio/${LAKEHOUSE_NAME};
      tail -f /dev/null;
      "
    depends_on:
      - minio

  # Trino
  trino:
    image: trinodb/trino:437
    container_name: trino
    ports:
      - 8080:8080
    environment:
      - AWS_REGION=${AWS_REGION}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - S3_ENDPOINT=${S3_ENDPOINT}
      - LAKEHOUSE_NAME=${LAKEHOUSE_NAME}
    volumes:
      - ./trino/etc:/etc/trino
    networks:
      - shared_network
    depends_on:
      - minio

  # Superset
  superset-cache:
    image: redis:7
    container_name: superset_cache
    restart: unless-stopped
    volumes:
      - superset_cache:/data
    networks:
      - shared_network

  superset-db:
    env_file: superset/docker/.env
    image: postgres:15
    container_name: superset_db
    restart: unless-stopped
    volumes:
      - superset_db_home:/var/lib/postgresql/data
    networks:
      - shared_network

  superset:
    env_file: superset/docker/.env
    image: *superset-image
    container_name: superset_app
    command: ['/app/docker/docker-bootstrap.sh', 'app-gunicorn']
    user: 'root'
    restart: unless-stopped
    ports:
      - 8088:8088
    depends_on: *superset-depends-on
    volumes: *superset-volumes
    networks:
      - shared_network

  superset-init:
    image: *superset-image
    container_name: superset_init
    command: ['/app/docker/docker-init.sh']
    env_file: superset/docker/.env
    depends_on: *superset-depends-on
    user: 'root'
    volumes: *superset-volumes
    healthcheck:
      disable: true
    networks:
      - shared_network

  superset-worker:
    image: *superset-image
    container_name: superset_worker
    command: ['/app/docker/docker-bootstrap.sh', 'worker']
    env_file: superset/docker/.env
    restart: unless-stopped
    depends_on: *superset-depends-on
    user: 'root'
    volumes: *superset-volumes
    healthcheck:
      test: ['CMD-SHELL', 'celery -A superset.tasks.celery_app:app inspect ping -d celery@$$HOSTNAME']
    networks:
      - shared_network

  superset-worker-beat:
    image: *superset-image
    container_name: superset_worker_beat
    command: ['/app/docker/docker-bootstrap.sh', 'beat']
    env_file: superset/docker/.env
    restart: unless-stopped
    depends_on: *superset-depends-on
    user: 'root'
    volumes: *superset-volumes
    healthcheck:
      disable: true
    networks:
      - shared_network

volumes:
  pg_catalog_data:
  minio_data:
  superset_home:
    external: false
  superset_db_home:
    external: false
  superset_cache:
    external: false

networks:
  shared_network:
    driver: bridge
